{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "from tqdm.notebook import tqdm\n",
    "import scipy\n",
    "import scipy.sparse\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import scipy.sparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import pickle\n",
    "import bz2\n",
    "import shutil\n",
    "from bz2 import BZ2Compressor\n",
    "import random\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as torch_data\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import shutil\n",
    "\n",
    "from file_utils import saver_state, loader_state, shuffle, compressed_read, compressed_write, decompress\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import PackedSequence\n",
    "from typing import *\n",
    "\n",
    "from models import LM, Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do hard drive-friendly read and write?\n",
    "do_compression = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Delte old data if there is. Recreate data directories.\n",
    "\n",
    "path = os.path.join(\"nn_data\",\"train\")\n",
    "if os.path.isdir(path):\n",
    "    shutil.rmtree(path)\n",
    "os.mkdir(os.path.join(\"nn_data\",\"train\"))\n",
    "\n",
    "path = os.path.join(\"nn_data\",\"dev\")\n",
    "if os.path.isdir(path):\n",
    "    shutil.rmtree(path)\n",
    "os.mkdir(os.path.join(\"nn_data\",\"dev\"))\n",
    "\n",
    "path = os.path.join(\"nn_data\",\"train_lm\")\n",
    "if os.path.isdir(path):\n",
    "    shutil.rmtree(path)\n",
    "os.mkdir(os.path.join(\"nn_data\",\"train_lm\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#copy data from read only directory to work directory\n",
    "for i in range(12):\n",
    "    shutil.copy(os.path.join(\"nn_data\",\"clear\",\"chunk\"+str(i)+\".bz2\"), os.path.join(\"nn_data\",\"train\"))\n",
    "\n",
    "for i in range(12):\n",
    "    shutil.copy(os.path.join(\"nn_data\",\"clear\",\"chunk\"+str(i)+\".bz2\"), os.path.join(\"nn_data\",\"train_lm\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6466c761f5394d2da242ea62daa387a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f891580eef54f54b3fc074b5d5f891c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#if not flag than do not perform compression due to speed reasons            \n",
    "if(do_compression == False):\n",
    "    decompress(\"train\")\n",
    "    decompress(\"train_lm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nn_data\\\\dev\\\\chunk11.bz2'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make classifier validation\n",
    "shutil.move(os.path.join(\"nn_data\",\"train\",\"chunk\"+str(10)+\".bz2\"), os.path.join(\"nn_data\",\"dev\",\"chunk\"+str(10)+\".bz2\"))\n",
    "shutil.move(os.path.join(\"nn_data\",\"train\",\"chunk\"+str(11)+\".bz2\"), os.path.join(\"nn_data\",\"dev\",\"chunk\"+str(11)+\".bz2\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be301fd9c39f44b9b3f9fcde3d810a0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8ea6d96df154ecca6dbdb5ae6f800ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fae94c83431d4e9aa14e4829ff49b6f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71d56aac155a4b09bec8a21caebbab4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "shuffle()\n",
    "shuffle(\"train_lm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load categorical to ids mapping\n",
    "with open('feat2id.pickle', 'rb') as handle:\n",
    "    feat2id = pickle.load(handle)\n",
    "\n",
    "with open('id2feat.pickle', 'rb') as handle:\n",
    "    id2feat = pickle.load(handle)\n",
    "\n",
    "with open('global_mapping.pickle', 'rb') as handle:\n",
    "    global_mapping = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_values = {}\n",
    "for ft in feat2id.keys():\n",
    "    MaxFeatureRange = len(global_mapping[ft])+1+1+1 #reserve space for special tokens\n",
    "    pad_values[ft] = MaxFeatureRange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#next example generator. Read files from chunk to chunk and yiel exaples from each chunk\n",
    "\n",
    "import string\n",
    "latters = list(string.ascii_uppercase)+list(string.ascii_lowercase)\n",
    "latters2id = {k:v for k,v in zip(latters, range(len(latters)))}\n",
    "id2latters = {v:k for k,v in latters2id.items()}\n",
    "\n",
    "def get_next_example(part = \"train\", avaliable_chunks=(0,1,2,3,4,5,6,7,8,9)):\n",
    "    for chunk_i in avaliable_chunks:\n",
    "        with open(os.path.join(\"nn_data\",part,\"chunk\"+str(chunk_i)+\".bz2\"), \"rb\") as f:\n",
    "            lines = compressed_read(f, do_compression = do_compression)\n",
    "        lines = lines.split('\\n')\n",
    "        for l in lines:\n",
    "            data = l.split(' ')\n",
    "            words = data[:-1]\n",
    "            y = data[-1]\n",
    "            \n",
    "            list_of_tokens_lists = [[latters2id[latter] for latter in word] for word in words]\n",
    "            \n",
    "            list_of_ids_lists = []\n",
    "            padding_shift = 3\n",
    "            \n",
    "            for tokl, nom in zip(list_of_tokens_lists, range(len(list_of_tokens_lists)) ):\n",
    "                list_of_ids_lists.append([global_mapping[id2feat[nom]][x] + padding_shift for x in tokl])\n",
    "            yield list_of_ids_lists + [int(y)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data convertion functions for autoencoder\n",
    "max_pos_len = 50\n",
    "def process_feature_lm(l, max_pos_len):\n",
    "    if(len(l) < max_pos_len):\n",
    "        return ([1] + l + [2] + [0]*(max_pos_len - len(l)), l + [2] + [0]*(max_pos_len - len(l)+1))\n",
    "    elif(len(l) > max_pos_len):\n",
    "        return ([1] + l[-max_pos_len:] + [2], l[-max_pos_len-1:] + [2])#[::-1]\n",
    "    else:\n",
    "        return ([1] + l + [2], l + [2] + [0])\n",
    "\n",
    "#gather examples into batch   \n",
    "def collate_fn_lm(batch_list, max_pos_len):\n",
    "    Xs = [[] for _ in range(len(id2feat))]\n",
    "    Ys = [[] for _ in range(len(id2feat))]\n",
    "    lens = []\n",
    "    lens_tech = []\n",
    "    \n",
    "    for example in batch_list:\n",
    "        l = example[0]\n",
    "        lens_tech.append(len(l) if(len(l) < max_pos_len) else max_pos_len)\n",
    "\n",
    "    for example in batch_list:\n",
    "        for i in range(len(id2feat)):\n",
    "            l = example[i]\n",
    "            if(i==0):\n",
    "                lens.append(len(l) + 2 if(len(l) < max_pos_len) else max_pos_len+2)\n",
    "                \n",
    "            x, y  = process_feature_lm(l, min(max_pos_len, max(lens_tech)))\n",
    "            Xs[i].append(x)\n",
    "            Ys[i].append(y)\n",
    "            #print(len(x), len(y))\n",
    "    \n",
    "    return ([torch.tensor(x, dtype=torch.int32) for x in Xs], [torch.tensor(y, dtype=torch.int64) for y in Ys], lens)\n",
    "\n",
    "#generate batches for autoencoder\n",
    "def batch_gen_lm(batch_size, max_pos_len = 50, part = \"train_lm\", avaliable_chunks=(0,1,2,3,4,5,6,7,8,9,10,11)):\n",
    "    batch_list = []\n",
    "    i = 0\n",
    "    for x in get_next_example(part, avaliable_chunks):\n",
    "        batch_list.append(x)\n",
    "        i += 1\n",
    "        if(i == batch_size):\n",
    "            yield collate_fn_lm(batch_list, max_pos_len)\n",
    "            batch_list = []\n",
    "            i = 0\n",
    "    if(len(batch_list)>0):\n",
    "        yield collate_fn_lm(batch_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data convertion functions for classifier\n",
    "def process_feature(l, max_pos_len):\n",
    "    if(len(l) < max_pos_len):\n",
    "        l = [1] + l  + [0]*(max_pos_len - len(l))\n",
    "    elif(len(l) > max_pos_len):\n",
    "        l = [1] + l[-max_pos_len:] #[::-1]\n",
    "    else:\n",
    "        l = [1] + l  #[::-1]\n",
    "    return l\n",
    "\n",
    "#gather examples into batch\n",
    "def collate_fn(batch_list, max_pos_len):\n",
    "    feat_lists = [[] for _ in range(len(id2feat))]\n",
    "    y = []\n",
    "    lens = []\n",
    "    for example in batch_list:\n",
    "        for i in range(len(id2feat)):\n",
    "            l = example[i]\n",
    "            if(i==0):\n",
    "                lens.append(len(l) + 1 if(len(l) < max_pos_len) else max_pos_len+1)\n",
    "            l  = process_feature(l, max_pos_len)\n",
    "            feat_lists[i].append(l)\n",
    "        y.append(example[-1])\n",
    "    \n",
    "    return ([torch.tensor(x, dtype=torch.int32) for x in feat_lists], torch.tensor(y, dtype=torch.int64), lens)\n",
    "\n",
    "#generate batches for classifier\n",
    "def batch_gen(batch_size, max_pos_len = 50, part = \"train\", avaliable_chunks=(0,1,2,3,4,5,6,7,8,9)):\n",
    "    batch_list = []\n",
    "    i = 0\n",
    "    for x in get_next_example(part, avaliable_chunks):\n",
    "        batch_list.append(x)\n",
    "        i += 1\n",
    "        if(i == batch_size):\n",
    "            yield collate_fn(batch_list, max_pos_len)\n",
    "            batch_list = []\n",
    "            i = 0\n",
    "    if(len(batch_list)>0):\n",
    "        yield collate_fn(batch_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding size [18, 16, 16, 16, 16, 16, 18, 10, 8, 4, 6, 14, 16, 18, 12, 8, 12, 4, 4, 4, 4, 4, 18, 18, 18, 4, 4, 4, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 10, 10, 10, 6, 4, 4]\n",
      "embedding size [18, 16, 16, 16, 16, 16, 18, 10, 8, 4, 6, 14, 16, 18, 12, 8, 12, 4, 4, 4, 4, 4, 18, 18, 18, 4, 4, 4, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 10, 10, 10, 6, 4, 4]\n"
     ]
    }
   ],
   "source": [
    "model = LM(id2feat, pad_values)\n",
    "classifier_model = Net(id2feat, pad_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "optimizer_lm = optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion_lm = nn.NLLLoss(ignore_index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classifier evaluation\n",
    "def eval_dev_classifier(model, nbatch):\n",
    "    targets = []\n",
    "    preds = []\n",
    "    ii = 0\n",
    "    for X, y, lens in tqdm(batch_gen(1000, max_pos_len, \"dev\", (10,11))):\n",
    "        for i in range(len(X)):\n",
    "            X[i] = X[i].to(device)\n",
    "            y[i] = y[i].to(device)\n",
    "        tgt = y.numpy()\n",
    "        output = model(X, lens)[:,1] \n",
    "        pr = output.detach().cpu().numpy()\n",
    "        targets.append(tgt)\n",
    "        preds.append(np.exp(pr))\n",
    "        ii += 1\n",
    "        \n",
    "        if(ii>nbatch):\n",
    "            break\n",
    "    return roc_auc_score(np.hstack(targets), np.hstack(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import ExponentialLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classifier training\n",
    "def train_classifier(epoches_gone, experiment_name, device):\n",
    "    load_dir = os.path.join(experiment_name, \"lm_chekpoints\", str(epoches_gone), \"model.pt\")\n",
    "    model = loader_state(load_dir)\n",
    "    model.to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "    scheduler = ExponentialLR(optimizer, gamma = (1e-5/1e-3)**(1/(6000*7)))\n",
    "\n",
    "    loss_function = torch.nn.NLLLoss(weight=torch.tensor([1., 0.97/0.03]).to(device))#0.97/0.03\n",
    "    \n",
    "    logdir=os.path.join(experiment_name, \"classifier_logs\", str(epoches_gone))\n",
    "    \n",
    "    if os.path.isdir(logdir):\n",
    "        shutil.rmtree(logdir)\n",
    "\n",
    "    os.mkdir(logdir)\n",
    "\n",
    "    writer=SummaryWriter(log_dir=logdir)\n",
    "    \n",
    "    \n",
    "    model.train()\n",
    "    epoches=3\n",
    "    ii = 0\n",
    "    for ep in range(epoches):\n",
    "        for X, y, lens in tqdm(batch_gen(500, max_pos_len)):\n",
    "            for i in range(len(X)):\n",
    "                X[i] = X[i].to(device)\n",
    "            y = y.to(device)\n",
    "            output = model(X, lens)\n",
    "            loss = loss_function(output, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            scheduler.step()\n",
    "            writer.add_scalar('Loss/train', loss.item() , ii)\n",
    "            if(ii%100 == 0):\n",
    "                print(loss.item())\n",
    "            if(ii%500 == 0):\n",
    "                model.eval()\n",
    "                ev = eval_dev_classifier(model, 50)\n",
    "                print(\"after\",ii,\"steps short auc dev\", ev)\n",
    "                writer.add_scalar('auc dev short', ev , ii)\n",
    "                model.train()\n",
    "            ii+=1\n",
    "        #break\n",
    "        model.eval()\n",
    "        ev = eval_dev_classifier(model, 10**4)\n",
    "        print(\"after\",ep,\"epoches full auc dev\", ev)\n",
    "        writer.add_scalar('auc dev long', ev , ii)\n",
    "        model.train()\n",
    "        shuffle(\"train\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = 'with_test_nn2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#manage log directories\n",
    "if os.path.isdir(experiment_name):\n",
    "    shutil.rmtree(experiment_name)\n",
    "\n",
    "os.mkdir(experiment_name)\n",
    "os.mkdir(os.path.join(experiment_name, \"lm_chekpoints\"))\n",
    "os.mkdir(os.path.join(experiment_name, \"classifier_logs\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dca0c06d2f5f4984855f05f2cb8c685f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:815: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
      "D:\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8712790608406067\n",
      "0.7818545699119568\n",
      "0.7233870029449463\n",
      "0.6848558187484741\n",
      "0.7006369233131409\n",
      "0.6945775151252747\n",
      "0.657108724117279\n",
      "0.6356131434440613\n",
      "0.6248583793640137\n",
      "0.6150219440460205\n",
      "0.6237711906433105\n",
      "0.6269310712814331\n",
      "0.6181519031524658\n",
      "0.5937729477882385\n",
      "0.579681396484375\n",
      "0.587653636932373\n",
      "0.5703003406524658\n",
      "0.591055154800415\n",
      "0.572417676448822\n",
      "0.5812262296676636\n",
      "0.5671764612197876\n",
      "0.552343487739563\n",
      "0.566238522529602\n",
      "0.5516991019248962\n"
     ]
    }
   ],
   "source": [
    "#autoencoder pretraining \n",
    "#run 5 epoch. I pretrain model on all avaliable data. Save state after each epoch\n",
    "model.train()\n",
    "epoches=1\n",
    "ii = 0\n",
    "for ep in range(epoches):\n",
    "    for X, y, lens in tqdm(batch_gen_lm(1000, max_pos_len)):\n",
    "        for i in range(len(X)):\n",
    "            X[i] = X[i].to(device)\n",
    "            y[i] = y[i].to(device)\n",
    "        output = model(X, lens)\n",
    "        ct = []\n",
    "        for i in range(len(X)):\n",
    "            ct.append(criterion_lm(output[i], y[i]))\n",
    "            \n",
    "        loss = torch.stack(ct).mean()\n",
    "        loss.backward()\n",
    "        optimizer_lm.step()\n",
    "        optimizer_lm.zero_grad()\n",
    "        \n",
    "        if((ii+1)%100 == 0):\n",
    "            print(loss.item())\n",
    "        ii+=1\n",
    "        \n",
    "    os.mkdir(os.path.join(experiment_name, \"lm_chekpoints\", str(ep)))\n",
    "    \n",
    "    saver_state(model, os.path.join(experiment_name, \"lm_chekpoints\", str(ep), \"model.pt\"))\n",
    "\n",
    "    shuffle(\"train_lm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model\n",
    "del optimizer_lm\n",
    "del X\n",
    "del y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding size [9, 8, 8, 8, 8, 8, 9, 5, 4, 2, 3, 7, 7, 9, 6, 4, 5, 2, 2, 2, 2, 2, 9, 9, 9, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 5, 5, 5, 3, 2, 2]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "391cccb2a74840e8b32a12603627ad32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0004462003707886\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "134c59ea6c8a449d9f6b537c67bf3336",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after 0 steps short auc dev 0.48258688902005115\n",
      "0.6192314028739929\n",
      "0.5748345851898193\n",
      "0.6302871704101562\n",
      "0.5617143511772156\n",
      "0.5921562910079956\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36423f23d14842edb88e0c85c5090b9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after 500 steps short auc dev 0.7160145390827194\n",
      "0.5847004652023315\n",
      "0.5570023059844971\n",
      "0.6123784780502319\n",
      "0.5856219530105591\n",
      "0.5673748254776001\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec56809516a54b1da48594488c41de59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after 1000 steps short auc dev 0.7284566344633256\n",
      "0.5587698817253113\n",
      "0.5856814384460449\n",
      "0.6366331577301025\n",
      "0.5292481780052185\n",
      "0.6198101043701172\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8828324bac7c49c98b851ffc97d23965",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after 1500 steps short auc dev 0.7304860883736771\n",
      "0.5615350008010864\n",
      "0.6070448160171509\n",
      "0.6122964024543762\n",
      "0.5485662817955017\n",
      "0.5461611151695251\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6eb79d1ec104c83945562f381da3a6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after 2000 steps short auc dev 0.7364831906581121\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-728fed73b255>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mtrain_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexperiment_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-35-ea7cd8b6751e>\u001b[0m in \u001b[0;36mtrain_classifier\u001b[1;34m(epoches_gone, experiment_name, device)\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0mii\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlens\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_gen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_pos_len\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m                 \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\testenv\\lib\\site-packages\\tqdm\\notebook.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    256\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m             \u001b[0mit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 258\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    259\u001b[0m                 \u001b[1;31m# return super(tqdm...) will not catch exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m                 \u001b[1;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\testenv\\lib\\site-packages\\tqdm\\std.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1193\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1194\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1195\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1196\u001b[0m                 \u001b[1;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1197\u001b[0m                 \u001b[1;31m# Update and possibly print the progressbar.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-33-d4924321e0d6>\u001b[0m in \u001b[0;36mbatch_gen\u001b[1;34m(batch_size, max_pos_len, part, avaliable_chunks)\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[0mbatch_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mget_next_example\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mavaliable_chunks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m         \u001b[0mbatch_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0mi\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-ea273aa2e44e>\u001b[0m in \u001b[0;36mget_next_example\u001b[1;34m(part, avaliable_chunks)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mtokl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnom\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist_of_tokens_lists\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist_of_tokens_lists\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m                 \u001b[0mlist_of_ids_lists\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mglobal_mapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mid2feat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnom\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mpadding_shift\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtokl\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m             \u001b[1;32myield\u001b[0m \u001b[0mlist_of_ids_lists\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-ea273aa2e44e>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mtokl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnom\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist_of_tokens_lists\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist_of_tokens_lists\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m                 \u001b[0mlist_of_ids_lists\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mglobal_mapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mid2feat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnom\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mpadding_shift\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtokl\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m             \u001b[1;32myield\u001b[0m \u001b[0mlist_of_ids_lists\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#load weights from each checkpoint and check classifier's performance\n",
    "for ep in range(5):\n",
    "    train_classifier(ep, experiment_name, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
